from sqlalchemy.orm import Session
from routers.langgraph_router import run_graph, research_app
import logging, httpx
from langchain_core.messages import BaseMessage, AIMessage
from openai import AsyncOpenAI
from database.dependencies import get_db
from database.models import Setting
import asyncio


logger = logging.getLogger(__name__)


def _pick_final_answer(messages: list[BaseMessage]) -> str | None:
    for m in reversed(messages):
        if isinstance(m, AIMessage) and getattr(m, "content", None):
            return m.content
    return None

# 1) ê·¸ë˜í”„ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë‹µë³€ ìƒì„± í•¨ìˆ˜
async def generate_answer_via_graph(utterance: str, user_id: str):
    output = await run_graph(research_app, utterance, user_id)
    if output and isinstance(output, dict):
        messages = output.get("messages", []) or []
        ai_text = _pick_final_answer(messages)

        # ì—ì½”ë°©ì§€
        if ai_text and utterance and ai_text.strip() == utterance.strip():
            ai_text = "ë°©ê¸ˆ ë§ì”€í•˜ì‹  ë‚´ìš©ì„ í™•ì¸í–ˆì–´ìš”. ì–´ë–¤ ì ì´ ë” ê¶ê¸ˆí•˜ì‹ ê°€ìš”? ğŸ™‚"

        if ai_text:
            return ai_text[:800]

    logger.error("ìœ íš¨í•œ ìµœì¢… ìƒíƒœë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. State: %s", output)
    return "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."


async def LGsend_callback(answer_text: str, callback_url: str):
    """
    ìƒì„±ëœ ë‹µë³€ì„ ì¹´ì¹´ì˜¤í†¡ì˜ callbackUrlë¡œ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜
    """
    payload = {
        "version": "2.0",
        "template": {
            "outputs": [
                {
                    "simpleText": {
                        "text": answer_text
                    }
                }
            ]
        }
    }

    try:
        # ë¹„ë™ê¸° HTTP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•´ POST ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
        async with httpx.AsyncClient() as client:
            response = await client.post(callback_url, json=payload, timeout=5)
            response.raise_for_status()  # 2xx ì‘ë‹µì´ ì•„ë‹ˆë©´ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.
        logger.info(f"Callback to {callback_url} successful, response: {response.text}")
    except httpx.RequestError as e:
        logger.error(f"Failed to send callback to {callback_url}: {e}")
    except Exception as e:
        logger.error(f"An unexpected error occurred during callback: {e}")



openai_api_key = next(get_db()).query(Setting).first().key

# 2) ì´ë¯¸ì§€ ë‹µë³€ í•¨ìˆ˜
async def generate_answer_image(utterance: str, image_url: str, db:Session, user_id: str):
    client = AsyncOpenAI(api_key=openai_api_key)
    logger.info(f"ì´ë¯¸ì§€ ë‹µë³€ í•¨ìˆ˜ì—ì„œ ë³´ëŠ” image_urlì€ {image_url}")

    # ìš”ì²­í•  ë©”ì‹œì§€ êµ¬ì„±
    response = await client.responses.create(
        model="gpt-4o",
        input=[
        {
            "role": "user",
            "content": [
                {"type":"input_text","text":utterance},
                {"type":"input_image","image_url": image_url}
            ]
        }
    ]
)
    logger.info(f"assistant ë‹µë³€: {response}")
    answers = response.output_text



    return answers



# 3) BackgroundTasks ì— ì˜ˆì•½í•  í•¨ìˆ˜ (ì´ê²Œ FastAPI ì½”ë“œì—ì„œ í˜¸ì¶œë©ë‹ˆë‹¤)
async def LGgenerate_and_send_answer(utterance: str, user_id: str, callback_url: str, db: Session, image_url: str = None):
    logger.info(f"âœ… [LG ë°±ê·¸ë¼ìš´ë“œ ì‹œì‘] user: {user_id}, utterance: {utterance}")
    try:
        answer = None # ë‹µë³€ ë³€ìˆ˜ ì´ˆê¸°í™”

        if image_url is None:
            logger.info("â¡ï¸ [LG] í…ìŠ¤íŠ¸ ë‹µë³€ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            answer = await generate_answer_via_graph(utterance, user_id) 
            logger.info(f"â¬…ï¸ [LG] í…ìŠ¤íŠ¸ ë‹µë³€ ìƒì„± ì™„ë£Œ: {answer}")
        else:
            logger.info("â¡ï¸ [LG] ì´ë¯¸ì§€ ë‹µë³€ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            answer = await generate_answer_image(utterance, image_url, db, user_id)
            logger.info(f"â¬…ï¸ [LG] ì´ë¯¸ì§€ ë‹µë³€ ìƒì„± ì™„ë£Œ: {answer}")

        if answer:
            logger.info(f"ğŸš€ [LG] ì½œë°± ì „ì†¡ì„ ì‹œì‘í•©ë‹ˆë‹¤. URL: {callback_url}")
            await LGsend_callback(answer, callback_url)
            logger.info("âœ… [LG ë°±ê·¸ë¼ìš´ë“œ ì„±ê³µ] ì½œë°± ì „ì†¡ ì™„ë£Œ.")
        else:
            logger.error("â—ï¸ [LG] ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (ê²°ê³¼ê°€ None ë˜ëŠ” ë¹„ì–´ìˆìŒ).")
            await LGsend_callback("ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", callback_url)

    except Exception as e:
        logger.critical(f"ğŸ”¥ [LG ë°±ê·¸ë¼ìš´ë“œ ì˜¤ë¥˜] ì‘ì—… ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
        error_message = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        await LGsend_callback(error_message, callback_url)
